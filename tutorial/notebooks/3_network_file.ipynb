{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Network File\n",
    "\n",
    "In this notebook, we compile the seismic network metadata that will be used recurrently through the workflow. We also scan the whole preprocessed data set to measure the daily data availability, which is essential for estimating the detection capability of the network at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import obspy as obs\n",
    "\n",
    "from BPMF.config import cfg\n",
    "from matplotlib.ticker import FixedLocator, FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_FILENAME = \"network.csv\"\n",
    "AVAILABILITY_FILENAME = \"availability.csv\"\n",
    "preproc_folder_name = f\"preprocessed_{cfg.MIN_FREQ_HZ:.0f}_{cfg.MAX_FREQ_HZ:.0f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-07-07'], dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we check the station metadata and data availability between START_DATE and END_DATE\n",
    "# these also define the start and end of the experiment\n",
    "START_DATE = \"2012-07-07\"\n",
    "END_DATE = \"2012-07-07\"\n",
    "datelist = pd.date_range(start=START_DATE, end=END_DATE)\n",
    "datelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data frames\n",
    "daily_availability = pd.DataFrame()\n",
    "network_metadata = pd.DataFrame(\n",
    "    columns=[\"network_code\", \"station_code\", \"longitude\", \"latitude\", \"elevation_m\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# even though this tutorial analyzes a single day, this notebook is written for an extended\n",
    "# data base following the folder tree convention used here\n",
    "for date in datelist:\n",
    "    row_name = date.strftime(\"%Y-%m-%d\")\n",
    "    data_folder = os.path.join(\n",
    "        cfg.INPUT_PATH, str(date.year), date.strftime(\"%Y%m%d\"), preproc_folder_name\n",
    "    )\n",
    "    resp_folder = os.path.join(\n",
    "        cfg.INPUT_PATH, str(date.year), date.strftime(\"%Y%m%d\"), \"resp\"\n",
    "    )\n",
    "    data_filenames = glob.glob(os.path.join(data_folder, \"*mseed\"))\n",
    "    daily_network_metadata = pd.DataFrame(\n",
    "        columns=[\"network_code\", \"station_code\", \"longitude\", \"latitude\", \"elevation_m\"]\n",
    "    )\n",
    "    for fname in data_filenames:\n",
    "        # we are only interested in the filename, not the entire path\n",
    "        fname = os.path.basename(fname)\n",
    "        # the filename contains information on the channel id\n",
    "        net_code, sta_code, loc_code, cha_code, ext = fname.split(\".\")\n",
    "        cha_code = cha_code[: cha_code.find(\"_\")]\n",
    "        # print(net_code, sta_code, loc_code, cha_code)\n",
    "        daily_network_metadata.loc[\n",
    "            f\"{net_code}.{sta_code}\", [\"network_code\", \"station_code\"]\n",
    "        ] = [net_code, sta_code]\n",
    "    \n",
    "    for sta_id in daily_network_metadata.index:\n",
    "        # count the number of channels associated with sta_id\n",
    "        channels = fnmatch.filter(data_filenames, f\"*{sta_id}.*mseed\")\n",
    "        daily_availability.loc[row_name, sta_id] = len(channels)\n",
    "        if sta_id not in network_metadata.index:\n",
    "            station_inv = obs.read_inventory(\n",
    "                os.path.join(resp_folder, f\"{sta_id}.xml\")\n",
    "            )[0][0]\n",
    "            daily_network_metadata.loc[\n",
    "                sta_id, [\"longitude\", \"latitude\", \"elevation_m\"]\n",
    "            ] = [station_inv.longitude, station_inv.latitude, station_inv.elevation]\n",
    "    network_metadata = pd.concat([network_metadata, daily_network_metadata]).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network_code</th>\n",
       "      <th>station_code</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>elevation_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YH.SAUV</th>\n",
       "      <td>YH</td>\n",
       "      <td>SAUV</td>\n",
       "      <td>30.3272</td>\n",
       "      <td>40.7402</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DE07</th>\n",
       "      <td>YH</td>\n",
       "      <td>DE07</td>\n",
       "      <td>30.411539</td>\n",
       "      <td>40.679661</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DC07</th>\n",
       "      <td>YH</td>\n",
       "      <td>DC07</td>\n",
       "      <td>30.24217</td>\n",
       "      <td>40.66708</td>\n",
       "      <td>164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DD06</th>\n",
       "      <td>YH</td>\n",
       "      <td>DD06</td>\n",
       "      <td>30.31777</td>\n",
       "      <td>40.623539</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.SPNC</th>\n",
       "      <td>YH</td>\n",
       "      <td>SPNC</td>\n",
       "      <td>30.3083</td>\n",
       "      <td>40.686001</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DE08</th>\n",
       "      <td>YH</td>\n",
       "      <td>DE08</td>\n",
       "      <td>30.406469</td>\n",
       "      <td>40.748562</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DC08</th>\n",
       "      <td>YH</td>\n",
       "      <td>DC08</td>\n",
       "      <td>30.25013</td>\n",
       "      <td>40.744438</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DC06</th>\n",
       "      <td>YH</td>\n",
       "      <td>DC06</td>\n",
       "      <td>30.265751</td>\n",
       "      <td>40.616718</td>\n",
       "      <td>555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.SAUV</th>\n",
       "      <td>YH</td>\n",
       "      <td>SAUV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DE07</th>\n",
       "      <td>YH</td>\n",
       "      <td>DE07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DC07</th>\n",
       "      <td>YH</td>\n",
       "      <td>DC07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DD06</th>\n",
       "      <td>YH</td>\n",
       "      <td>DD06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.SPNC</th>\n",
       "      <td>YH</td>\n",
       "      <td>SPNC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DE08</th>\n",
       "      <td>YH</td>\n",
       "      <td>DE08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DC08</th>\n",
       "      <td>YH</td>\n",
       "      <td>DC08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YH.DC06</th>\n",
       "      <td>YH</td>\n",
       "      <td>DC06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        network_code station_code  longitude   latitude elevation_m\n",
       "YH.SAUV           YH         SAUV    30.3272    40.7402       170.0\n",
       "YH.DE07           YH         DE07  30.411539  40.679661        40.0\n",
       "YH.DC07           YH         DC07   30.24217   40.66708       164.0\n",
       "YH.DD06           YH         DD06   30.31777  40.623539       182.0\n",
       "YH.SPNC           YH         SPNC    30.3083  40.686001       190.0\n",
       "YH.DE08           YH         DE08  30.406469  40.748562        31.0\n",
       "YH.DC08           YH         DC08   30.25013  40.744438       162.0\n",
       "YH.DC06           YH         DC06  30.265751  40.616718       555.0\n",
       "YH.SAUV           YH         SAUV        NaN        NaN         NaN\n",
       "YH.DE07           YH         DE07        NaN        NaN         NaN\n",
       "YH.DC07           YH         DC07        NaN        NaN         NaN\n",
       "YH.DD06           YH         DD06        NaN        NaN         NaN\n",
       "YH.SPNC           YH         SPNC        NaN        NaN         NaN\n",
       "YH.DE08           YH         DE08        NaN        NaN         NaN\n",
       "YH.DC08           YH         DC08        NaN        NaN         NaN\n",
       "YH.DC06           YH         DC06        NaN        NaN         NaN"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YH.SAUV</th>\n",
       "      <th>YH.DE07</th>\n",
       "      <th>YH.DC07</th>\n",
       "      <th>YH.DD06</th>\n",
       "      <th>YH.SPNC</th>\n",
       "      <th>YH.DE08</th>\n",
       "      <th>YH.DC08</th>\n",
       "      <th>YH.DC06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-07-07</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            YH.SAUV  YH.DE07  YH.DC07  ...  YH.DE08  YH.DC08  YH.DC06\n",
       "2012-07-07      3.0      3.0      3.0  ...      3.0      3.0      3.0\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the network metadata and data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'network'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/ebeauce/TUTO_BPMF/scripts/3_network_file.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypo-7.ldeo.columbia.edu/home/ebeauce/TUTO_BPMF/scripts/3_network_file.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m network_metadata\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstation_id\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bhypo-7.ldeo.columbia.edu/home/ebeauce/TUTO_BPMF/scripts/3_network_file.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m network_metadata\u001b[39m.\u001b[39;49mto_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(cfg\u001b[39m.\u001b[39;49mNETWORK_PATH, NETWORK_FILENAME), sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypo-7.ldeo.columbia.edu/home/ebeauce/TUTO_BPMF/scripts/3_network_file.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# add two header lines\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bhypo-7.ldeo.columbia.edu/home/ebeauce/TUTO_BPMF/scripts/3_network_file.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(cfg\u001b[39m.\u001b[39mNETWORK_PATH, NETWORK_FILENAME), \u001b[39m\"\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fnet:\n",
      "File \u001b[0;32m~/miniconda3/envs/hy7_py310/lib/python3.10/site-packages/pandas/core/generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3540\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3542\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3543\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3544\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3548\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3549\u001b[0m )\n\u001b[0;32m-> 3551\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3552\u001b[0m     path_or_buf,\n\u001b[1;32m   3553\u001b[0m     line_terminator\u001b[39m=\u001b[39;49mline_terminator,\n\u001b[1;32m   3554\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3555\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3556\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3557\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3558\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3559\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3560\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3561\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3562\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3563\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3564\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3565\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3566\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3567\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3568\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/hy7_py310/lib/python3.10/site-packages/pandas/io/formats/format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1162\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1163\u001b[0m     line_terminator\u001b[39m=\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1179\u001b[0m )\n\u001b[0;32m-> 1180\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1182\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1183\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/miniconda3/envs/hy7_py310/lib/python3.10/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[1;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[1;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/miniconda3/envs/hy7_py310/lib/python3.10/site-packages/pandas/io/common.py:697\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[0;32m--> 697\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[1;32m    699\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    701\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hy7_py310/lib/python3.10/site-packages/pandas/io/common.py:571\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    569\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 571\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'network'"
     ]
    }
   ],
   "source": [
    "network_metadata.index.name = \"station_id\"\n",
    "network_metadata.to_csv(os.path.join(cfg.NETWORK_PATH, NETWORK_FILENAME), sep=\"\\t\")\n",
    "# add two header lines\n",
    "with open(os.path.join(cfg.NETWORK_PATH, NETWORK_FILENAME), \"r+\") as fnet:\n",
    "    content = fnet.read()\n",
    "    # move pointer to beginning of file\n",
    "    fnet.seek(0, 0)\n",
    "    # append lines at the beginning\n",
    "    fnet.write(f\"{START_DATE}\\t{END_DATE}\\n\")\n",
    "    # write the name of the components used on each station\n",
    "    # note: the list of components will be used to broadcast\n",
    "    # network waveforms into a single numpy.ndarray, so even\n",
    "    # if some stations only have one component we need to \n",
    "    # fill their missing components with zeros in order to\n",
    "    # keep consistent data dimensions across stations\n",
    "    fnet.write(f\"N\\tE\\tZ\\n\")\n",
    "    fnet.write(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('hy7_py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "221f0e5b1b98151b07a79bf3b6d0c1d306576197d2c4531763770570a29e708e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
